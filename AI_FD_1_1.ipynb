{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_FD_1.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LXAwrJiR2oL"
      },
      "source": [
        "# 홍익대학교 컴퓨터공학과\n",
        "# 2021년 1학기 인공지능 프로젝트 <사기 결제 탐지>\n",
        "팀원(분반) : B511198 조일우(1) / B611125 유민호(2) / B511156 이치현(2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIf_cwG2R0Dj"
      },
      "source": [
        "# Must Mount Google drive with \"/Share/CreditCard_data/\" Directory.\n",
        "# x_train(Feature Data) : /content/drive/MyDrive/Share/CreditCard_Data/X_train.csv\n",
        "# y_train(Label Data) : /content/drive/MyDrive/Share/CreditCard_Data/y_train.csv\n",
        "# x_test(Feature Data) : /content/drive/MyDrive/Share/CreditCard_Data/X_test.csv\n",
        "# y_test(Label Data) : /content/drive/MyDrive/Share/CreditCard_Data/y_test.csv\n",
        "\n",
        "# 참고\n",
        "# 1. TensorFlow Keras Tutorials : https://www.tensorflow.org/tutorials/keras/classification?hl=ko\n",
        "# 2. TensorFlow Keras save and load Tutorials : https://www.tensorflow.org/guide/keras/save_and_serialize?hl=ko\n",
        "# 3. Try and Except : https://wikidocs.net/30\n",
        "# 4. Keras custom class Tutorials : https://bit.ly/3f8iE6v\n",
        "# 5. DNN example : https://corock.tistory.com/451\n",
        "# 6. Keras Precision, Recall, f1-score Code : https://m.blog.naver.com/PostView.naver?blogId=wideeyed&logNo=221226716255\n",
        "# 7. sklearn.metircs : https://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO-wGhqyT4Mz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "680ce1f1-3ec7-4bf2-af55-f06a897717bc"
      },
      "source": [
        "# import libs.\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# Check the version\\nprint(\"Tensor Version : \" + str(tf.__version__))\\nprint(\"Tensor Version : \" + str(tf.keras.__version__))\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYDfwB8nVjjK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15a6e8bf-93b5-4228-d6e5-cfb2ffa88766"
      },
      "source": [
        "# Data Links\n",
        "x_tr = '/content/drive/MyDrive/Share/CreditCard_Data/X_train.csv'\n",
        "y_tr = '/content/drive/MyDrive/Share/CreditCard_Data/y_train.csv'\n",
        "\n",
        "x_te = '/content/drive/MyDrive/Share/CreditCard_Data/X_test.csv'\n",
        "y_te = '/content/drive/MyDrive/Share/CreditCard_Data/y_test.csv'\n",
        "\n",
        "# Make dataframes with datasets.\n",
        "df_x = pd.read_csv(x_tr, index_col=0)\n",
        "df_y = pd.read_csv(y_tr, index_col=0)\n",
        "df_xt = pd.read_csv(x_te, index_col=0)\n",
        "df_yt = pd.read_csv(y_te, index_col=0)\n",
        "\n",
        "'''\n",
        "#drop time\n",
        "df_x.drop(['Time'], axis=1)\n",
        "df_xt.drop(['Time'], axis=1)\n",
        "'''\n",
        "\n",
        "# Normalization\n",
        "sc = StandardScaler()\n",
        "df_x = sc.fit_transform(df_x)\n",
        "df_xt = sc.fit_transform(df_xt)\n",
        "\n",
        "# Oversampling the train data\n",
        "smote = SMOTE(random_state=11)\n",
        "df_x_s,df_y_s = smote.fit_sample(df_x,df_y)\n",
        "\n",
        "# Undersamping the test data\n",
        "df_xt_s, df_yt_s = RandomUnderSampler(random_state=0).fit_resample(df_x, df_y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqDeYlhklKC"
      },
      "source": [
        "# Generate model function\n",
        "def makeModel(input_dime, output_dime, layer_depth=10):\n",
        "  model = Sequential()\n",
        "  # Input layer\n",
        "  model.add(Dense(units=input_dime, kernel_initializer='uniform', input_dim=input_dime, activation=\"relu\", name=\"input_Layer\"))\n",
        "  # Hidden Layers\n",
        "  for x in range(layer_depth):\n",
        "    model.add(Dense(units=16, kernel_initializer='uniform', activation=\"relu\", name=\"hidden_layer_{:02}\".format(x)))\n",
        "    model.add(Dropout(0.25)) # Set Dropout Ratio to X\n",
        "  # Output Layer\n",
        "  model.add(Dense(output_dime, kernel_initializer='uniform', activation=\"sigmoid\", name=\"output_Layer\"))\n",
        "  # Compile the model\n",
        "  adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(loss=keras.losses.binary_crossentropy, optimizer=adam, metrics=['accuracy',tf.keras.metrics.Precision(name='Precision'),tf.keras.metrics.Recall(name='Recall')])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Diipuuh7ARhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf1040c-6518-40bf-adda-0f2258a80794"
      },
      "source": [
        "# Set Features, Hidden layers, and an output\n",
        "input_features = df_x.shape[1]\n",
        "num_layers = 5\n",
        "output = df_y.shape[1] # {0, 1}\n",
        "\n",
        "# Set fit() Arguments\n",
        "bat_size = 100\n",
        "epch = 3\n",
        "\n",
        "# change summary view\n",
        "# 0 turns on the summary // 1 turns off the summary\n",
        "show_summary = 1\n",
        "\n",
        "# Fit the model with the train dataset\n",
        "model = makeModel(input_features, output, num_layers)\n",
        "history = model.fit(df_x_s, df_y_s, batch_size=bat_size, epochs=epch)\n",
        "\n",
        "# Show the model's summary\n",
        "if show_summary == 0:\n",
        "  model.summary()\n",
        "\n",
        "# Evaluate the model with the test dataset\n",
        "print(\"Model Evaluation\")\n",
        "result = {0,}\n",
        "results = model.evaluate(df_xt_s, df_yt_s, batch_size=5)\n",
        "\n",
        "# Print Metrics\n",
        "print('== <Results> ==\\n', 'Accuracy ', results[1] * 100, '%\\n')\n",
        "f1score = 2 * (results[2]*results[3])/(results[2]+results[3])\n",
        "print('Precision \\t', results[2], '\\n')\n",
        "print('Recall \\t\\t', results[3], '\\n')\n",
        "print('f1-score \\t', f1score, '\\n')\n",
        "print('===============\\n')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "3184/3184 [==============================] - 10s 2ms/step - loss: 0.6932 - accuracy: 0.4998 - Precision: 0.4944 - Recall: 0.2823\n",
            "Epoch 2/3\n",
            "3184/3184 [==============================] - 8s 2ms/step - loss: 0.6932 - accuracy: 0.5011 - Precision: 0.5003 - Recall: 0.4670\n",
            "Epoch 3/3\n",
            "3184/3184 [==============================] - 8s 2ms/step - loss: 0.6932 - accuracy: 0.5001 - Precision: 0.5006 - Recall: 0.4704\n",
            "Model Evaluation\n",
            "118/118 [==============================] - 1s 1ms/step - loss: 0.6932 - accuracy: 0.5000 - Precision: 0.5003 - Recall: 0.4891\n",
            "== <Results> ==\n",
            " Accuracy  50.0 %\n",
            "\n",
            "Precision \t 0.5002939701080322 \n",
            "\n",
            "Recall \t\t 0.4890948534011841 \n",
            "\n",
            "f1-score \t 0.4946310290823799 \n",
            "\n",
            "===============\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}