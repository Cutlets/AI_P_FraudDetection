# -*- coding: utf-8 -*-
"""AI_FD_1.1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lgayPoqKj7wXGUzIRLuFa7oE36rNB6F3

# 홍익대학교 컴퓨터공학과
# 2021년 1학기 인공지능 프로젝트 <사기 결제 탐지>
팀원(분반) : B511198 조일우(1) / B611125 유민호(2) / B511156 이치현(2)
"""

# Must Mount Google drive with "/Share/CreditCard_data/" Directory.
# x_train(Feature Data) : /content/drive/MyDrive/Share/CreditCard_Data/X_train.csv
# y_train(Label Data) : /content/drive/MyDrive/Share/CreditCard_Data/y_train.csv
# x_test(Feature Data) : /content/drive/MyDrive/Share/CreditCard_Data/X_test.csv
# y_test(Label Data) : /content/drive/MyDrive/Share/CreditCard_Data/y_test.csv

# 참고
# 1. TensorFlow Keras Tutorials : https://www.tensorflow.org/tutorials/keras/classification?hl=ko
# 2. TensorFlow Keras save and load Tutorials : https://www.tensorflow.org/guide/keras/save_and_serialize?hl=ko
# 3. Try and Except : https://wikidocs.net/30
# 4. Keras custom class Tutorials : https://bit.ly/3f8iE6v
# 5. DNN example : https://corock.tistory.com/451
# 6. Keras Precision, Recall, f1-score Code : https://m.blog.naver.com/PostView.naver?blogId=wideeyed&logNo=221226716255
# 7. sklearn.metircs : https://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html

# import libs.
import sys
import pandas as pd
import numpy as np
import tensorflow as tf
import keras
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.preprocessing import StandardScaler

# Data Links
x_tr = '/content/drive/MyDrive/Share/CreditCard_Data/X_train.csv'
y_tr = '/content/drive/MyDrive/Share/CreditCard_Data/y_train.csv'

x_te = '/content/drive/MyDrive/Share/CreditCard_Data/X_test.csv'
y_te = '/content/drive/MyDrive/Share/CreditCard_Data/y_test.csv'

# Make dataframes with datasets.
df_x = pd.read_csv(x_tr, index_col=0)
df_y = pd.read_csv(y_tr, index_col=0)
df_xt = pd.read_csv(x_te, index_col=0)
df_yt = pd.read_csv(y_te, index_col=0)

'''
#drop time
df_x.drop(['Time'], axis=1)
df_xt.drop(['Time'], axis=1)
'''

# Normalization
sc = StandardScaler()
df_x = sc.fit_transform(df_x)
df_xt = sc.fit_transform(df_xt)

# Oversampling the train data
smote = SMOTE(random_state=11)
df_x_s,df_y_s = smote.fit_sample(df_x,df_y)

# Undersamping the test data
df_xt_s, df_yt_s = RandomUnderSampler(random_state=0).fit_resample(df_x, df_y)

# Generate model function
def makeModel(input_dime, output_dime, layer_depth=10):
  model = Sequential()
  # Input layer
  model.add(Dense(units=input_dime, kernel_initializer='uniform', input_dim=input_dime, activation="relu", name="input_Layer"))
  # Hidden Layers
  for x in range(layer_depth):
    model.add(Dense(units=16, kernel_initializer='uniform', activation="relu", name="hidden_layer_{:02}".format(x)))
    model.add(Dropout(0.25)) # Set Dropout Ratio to X
  # Output Layer
  model.add(Dense(output_dime, kernel_initializer='uniform', activation="sigmoid", name="output_Layer"))
  # Compile the model
  adam = keras.optimizers.Adam(learning_rate=0.001)
  model.compile(loss=keras.losses.binary_crossentropy, optimizer=adam, metrics=['accuracy',tf.keras.metrics.Precision(name='Precision'),tf.keras.metrics.Recall(name='Recall')])

  return model

# Set Features, Hidden layers, and an output
input_features = df_x.shape[1]
num_layers = 5
output = df_y.shape[1] # {0, 1}

# Set fit() Arguments
bat_size = 100
epch = 3

# change summary view
# 0 turns on the summary // 1 turns off the summary
show_summary = 1

# Fit the model with the train dataset
model = makeModel(input_features, output, num_layers)
history = model.fit(df_x_s, df_y_s, batch_size=bat_size, epochs=epch)

# Show the model's summary
if show_summary == 0:
  model.summary()

# Evaluate the model with the test dataset
print("Model Evaluation")
result = {0,}
results = model.evaluate(df_xt_s, df_yt_s, batch_size=5)

# Print Metrics
print('== <Results> ==\n', 'Accuracy ', results[1] * 100, '%\n')
f1score = 2 * (results[2]*results[3])/(results[2]+results[3])
print('Precision \t', results[2], '\n')
print('Recall \t\t', results[3], '\n')
print('f1-score \t', f1score, '\n')
print('===============\n')