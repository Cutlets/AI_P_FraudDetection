{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_FD_1.1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1lgayPoqKj7wXGUzIRLuFa7oE36rNB6F3",
      "authorship_tag": "ABX9TyM14qAthU+6xNiXCh1EC3fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cutlets/AI_P_FraudDetection/blob/main/AI_FD_1_1(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LXAwrJiR2oL"
      },
      "source": [
        "# 홍익대학교 컴퓨터공학과\n",
        "# 2021년 1학기 인공지능 프로젝트 <사기 결제 탐지>\n",
        "팀원(분반) : B511198 조일우(1) / B611125 유민호(2) / B511156 이치현(2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIf_cwG2R0Dj"
      },
      "source": [
        "# Must Mount Google drive with \"/Share/CreditCard_data/\" Directory.\n",
        "# x_train(Feature Data) : /content/drive/MyDrive/Share/CreditCard_Data/X_train.csv\n",
        "# y_train(Label Data) : /content/drive/MyDrive/Share/CreditCard_Data/y_train.csv\n",
        "# x_test(Feature Data) : /content/drive/MyDrive/Share/CreditCard_Data/X_test.csv\n",
        "# y_test(Label Data) : /content/drive/MyDrive/Share/CreditCard_Data/y_test.csv\n",
        "\n",
        "# 참고\n",
        "# 1. TensorFlow Keras Tutorials : https://www.tensorflow.org/tutorials/keras/classification?hl=ko\n",
        "# 2. TensorFlow Keras save and load Tutorials : https://www.tensorflow.org/guide/keras/save_and_serialize?hl=ko\n",
        "# 3. Try and Except : https://wikidocs.net/30\n",
        "# 4. Keras custom class Tutorials : https://bit.ly/3f8iE6v\n",
        "# 5. DNN example : https://corock.tistory.com/451\n",
        "# 6. Keras Precision, Recall, f1-score Code : https://m.blog.naver.com/PostView.naver?blogId=wideeyed&logNo=221226716255\n",
        "# 7. sklearn.metircs : https://datascienceschool.net/03%20machine%20learning/09.04%20%EB%B6%84%EB%A5%98%20%EC%84%B1%EB%8A%A5%ED%8F%89%EA%B0%80.html"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO-wGhqyT4Mz"
      },
      "source": [
        "# import libs.\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYDfwB8nVjjK"
      },
      "source": [
        "# Data Links\n",
        "x_tr = '/content/drive/MyDrive/Share/CreditCard_Data/X_train.csv'\n",
        "y_tr = '/content/drive/MyDrive/Share/CreditCard_Data/y_train.csv'\n",
        "\n",
        "x_te = '/content/drive/MyDrive/Share/CreditCard_Data/X_test.csv'\n",
        "y_te = '/content/drive/MyDrive/Share/CreditCard_Data/y_test.csv'\n",
        "\n",
        "# Make dataframes with datasets.\n",
        "df_x = pd.read_csv(x_tr, index_col=0)\n",
        "df_y = pd.read_csv(y_tr, index_col=0)\n",
        "df_xt = pd.read_csv(x_te, index_col=0)\n",
        "df_yt = pd.read_csv(y_te, index_col=0)\n",
        "\n",
        "'''\n",
        "#drop time\n",
        "df_x.drop(['Time'], axis=1)\n",
        "df_xt.drop(['Time'], axis=1)\n",
        "'''\n",
        "\n",
        "# Normalization\n",
        "sc = StandardScaler()\n",
        "df_x = sc.fit_transform(df_x)\n",
        "df_xt = sc.fit_transform(df_xt)\n",
        "\n",
        "# Oversampling the train data\n",
        "smote = SMOTE(random_state=11)\n",
        "df_x_s,df_y_s = smote.fit_sample(df_x,df_y)\n",
        "\n",
        "# Undersamping the test data\n",
        "df_xt_s, df_yt_s = RandomUnderSampler(random_state=0).fit_resample(df_xt, df_yt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrqDeYlhklKC"
      },
      "source": [
        "# Generate model function\n",
        "def makeModel(input_dime, output_dime, layer_depth=10):\n",
        "  model = Sequential()\n",
        "  # Input layer\n",
        "  model.add(Dense(units=input_dime, kernel_initializer='uniform', input_dim=input_dime, activation=\"relu\", name=\"input_Layer\"))\n",
        "  # Hidden Layers\n",
        "  for x in range(layer_depth):\n",
        "    model.add(Dense(units=16, kernel_initializer='uniform', activation=\"relu\", name=\"hidden_layer_{:02}\".format(x)))\n",
        "    model.add(Dropout(0.25)) # Set Dropout Ratio to X\n",
        "  # Output Layer\n",
        "  model.add(Dense(output_dime, kernel_initializer='uniform', activation=\"sigmoid\", name=\"output_Layer\"))\n",
        "  # Compile the model\n",
        "  adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(loss=keras.losses.binary_crossentropy, optimizer=adam, metrics=['accuracy',tf.keras.metrics.Precision(name='Precision'),tf.keras.metrics.Recall(name='Recall')])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Diipuuh7ARhP"
      },
      "source": [
        "# Set Features, Hidden layers, and an output\n",
        "input_features = df_x.shape[1]\n",
        "num_layers = 4\n",
        "output = df_y.shape[1] # {0, 1}\n",
        "\n",
        "# Set fit() Arguments\n",
        "bat_size = 100\n",
        "epch = 3\n",
        "\n",
        "# change summary view\n",
        "# 0 turns on the summary // 1 turns off the summary\n",
        "show_summary = 1\n",
        "\n",
        "# Fit the model with the train dataset\n",
        "model = makeModel(input_features, output, num_layers)\n",
        "history = model.fit(df_x_s, df_y_s, batch_size=bat_size, epochs=epch)\n",
        "\n",
        "# Show the model's summary\n",
        "if show_summary == 0:\n",
        "  model.summary()\n",
        "\n",
        "# Evaluate the model with the test dataset\n",
        "print(\"Model Evaluation\")\n",
        "result = {0,}\n",
        "results = model.evaluate(df_xt_s, df_yt_s, batch_size=1)\n",
        "\n",
        "# Print Metrics\n",
        "print('== <Results> ==\\n', 'Accuracy ', results[1] * 100, '%\\n')\n",
        "f1score = 2 * (results[2]*results[3])/(results[2]+results[3])\n",
        "print('Precision \\t', results[2], '\\n')\n",
        "print('Recall \\t\\t', results[3], '\\n')\n",
        "print('f1-score \\t', f1score, '\\n')\n",
        "print('===============\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}